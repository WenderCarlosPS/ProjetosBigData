# -*- coding: utf-8 -*-
"""Pos Gradução - Big Data - Exercecio01

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WOKhaFfO3GMk7aQ0EVyf2FO1-92xWeGr
"""

# analise_vendas.py
import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, desc, sum as spark_sum, countDistinct, to_date

def main(csv_path):
    spark = (SparkSession.builder
             .appName("AnaliseVendasEcommerce")
             .getOrCreate())

    print(f"Carregando dados de vendas do arquivo: {csv_path}")

    # Carregar CSV
    df = (spark.read.format("csv")
          .option("header", "true")
          .option("inferSchema", "true")
          .load(csv_path))

    # Adicionar coluna Valor_Total
    df = df.withColumn("Valor_Total", col("Preco") * col("Quantidade"))

    # Vendas totais por categoria
    print("\n--- Vendas Totais por Categoria ---")
    vendas_categoria = (df.groupBy("Categoria")
                          .agg(spark_sum("Valor_Total").alias("Total_Vendas"))
                          .orderBy(desc("Total_Vendas")))
    vendas_categoria.show()

    # Quantidade de pedidos por cidade
    print("\n--- Quantidade de Pedidos por Cidade ---")
    pedidos_cidade = (df.groupBy("Cidade")
                       .agg(countDistinct("ID_Pedido").alias("Total_Pedidos"))
                       .orderBy(desc("Total_Pedidos")))
    pedidos_cidade.show()

    # Evolução diária de vendas
    print("\n--- Evolução Diária de Vendas ---")
    df = df.withColumn("Data_Venda", to_date(col("Data_Venda"), "yyyy-MM-dd"))
    vendas_diarias = (df.groupBy("Data_Venda")
                        .agg(spark_sum("Valor_Total").alias("Total_Vendas"))
                        .orderBy("Data_Venda"))
    vendas_diarias.show()

    # Top produtos mais vendidos
    print("\n--- Top Produtos por Valor Total ---")
    top_produtos = (df.groupBy("ID_Produto")
                      .agg(spark_sum("Valor_Total").alias("Total_Vendas"))
                      .orderBy(desc("Total_Vendas"))
                      .limit(10))
    top_produtos.show()

    spark.stop()

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Uso: spark-submit analise_vendas.py <caminho_para_o_csv>", file=sys.stderr)
        sys.exit(-1)

    csv_file_path = sys.argv[1]
    main(csv_file_path)